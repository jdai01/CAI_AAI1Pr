{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20b1690",
   "metadata": {},
   "source": [
    "# Support Vector Machines and Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac9a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today we use the support vector machine and the random forest classifier to make predictions for some data\n",
    "# This practical only contains a tiny amount of lines of code provided by you.\n",
    "# We will use sklearn library to make everything work.\n",
    "# Go through every notebook cell and implement the code on the areas where code is missing.\n",
    "# Data generation and plotting is already provided as methods below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f9924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset1():\n",
    "    X,y = make_blobs(n_samples = 90, centers = 2, random_state = 3)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032183e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset2():\n",
    "    # Create dataset\n",
    "    np.random.seed(42)  # always the same data generation\n",
    "    X = np.stack((np.random.normal(size=100),np.random.normal(size=100)),axis = 1)\n",
    "    y = np.array([1 if (xy[0]**2+xy[1]**2)**0.5 <0.5 else 0 for xy in X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd06f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(X, y):\n",
    "    # plot data\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], marker = '*', s=30)\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], marker = 'v', s=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801206b4",
   "metadata": {},
   "source": [
    "## 1) Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dfc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm_vectors(clf):\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], marker = '*', s=30)\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], marker = 'v', s=30)\n",
    "\n",
    "    # plot the decision function\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # create grid to evaluate model\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(\n",
    "        XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    "    )\n",
    "    # plot support vectors\n",
    "    ax.scatter(\n",
    "        clf.support_vectors_[:, 0],\n",
    "        clf.support_vectors_[:, 1],\n",
    "        s=100,\n",
    "        linewidth=1,\n",
    "        facecolors='none',\n",
    "        edgecolors=\"k\",\n",
    "    )\n",
    "    plt.title(\"Distance to hyperplane and support vectors\")\n",
    "    plt.ylabel('Feature y')\n",
    "    plt.xlabel('Feature x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12304018",
   "metadata": {},
   "source": [
    "### 1.1) Use a linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn and its svm implementation to fit the data into the model\n",
    "\n",
    "# your support vector machine from sklearn - code here\n",
    "clf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab654c",
   "metadata": {},
   "source": [
    "#### 1.1.1) Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset1()\n",
    "plot_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your SVM (fit method) from above with dataset 1 - write code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the decision boundaries of your svm\n",
    "# what do you think how good is your model based on this visualization?\n",
    "\n",
    "plot_svm_vectors(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8434b87",
   "metadata": {},
   "source": [
    "#### 1.1.2) Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc54299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset2()\n",
    "plot_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your SVM (fit method) from above with dataset 2 - write code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3442a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the decision boundaries of your svm\n",
    "# what do you think how good is your model based on this visualization?\n",
    "\n",
    "plot_svm_vectors(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a45a2",
   "metadata": {},
   "source": [
    "### 1.2) Use a polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ca694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial kernel (update code below)\n",
    "# what is an appropriate value of C?\n",
    "clf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643541cc",
   "metadata": {},
   "source": [
    "#### 1.2.1) Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e597a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset1()\n",
    "plot_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d28b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your SVM (fit method) from above with dataset 1 - write code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the decision boundaries of your svm\n",
    "# what do you think how good is your model based on this visualization?\n",
    "\n",
    "plot_svm_vectors(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e02225",
   "metadata": {},
   "source": [
    "#### 1.2.2) Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6098a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset2()\n",
    "plot_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30094d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your SVM (fit method) from above with dataset 1 - write code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the decision boundaries of your svm\n",
    "# what do you think how good is your model based on this visualization?\n",
    "\n",
    "plot_svm_vectors(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8650bb",
   "metadata": {},
   "source": [
    "## 2) Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b030f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y, y_pred):\n",
    "    res = y == y_pred\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn and its RandomForestClassifier implementation to fit the data into the model\n",
    "\n",
    "# your RandomForestClassifier from sklearn - code here\n",
    "# Start from a low number of estimators before you increase it step by step to see the prediction accuracy differences\n",
    "clf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb08cc3",
   "metadata": {},
   "source": [
    "### 2.1) Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e13738",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset1()\n",
    "plot_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f09141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into training and test data first\n",
    "# dataset split into 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e36fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your classifier (fit method) with dataset 1 (train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values with the test dataset of dataset 1\n",
    "# calculate the accuracy (use the method \"calculate_accuracy\" from above)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "calculate_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93580f0e",
   "metadata": {},
   "source": [
    "### 2.2) Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset2()\n",
    "plot_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a12056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into training and test data first\n",
    "# dataset split into 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2075880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your classifier (fit method) with dataset 1 (train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9752f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values with the test dataset of dataset 1\n",
    "# calculate the accuracy (use the method \"calculate_accuracy\" from above)\n",
    "# your code here!\n",
    "\n",
    "y_pred = ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
